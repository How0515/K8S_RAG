# Ollama LLM Server Deployment
# 대규모 언어 모델 서버 - 한국어 지원 gemma2:2b 모델 사용

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: rag-system
  labels:
    app: ollama
    component: llm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
        component: llm
    spec:
      containers:
        - name: ollama
          image: cow5757/ollama:latest
          ports:
            - containerPort: 11434
              name: http
          resources:
            requests:
              memory: "2Gi"
              cpu: "500m"
            limits:
              memory: "4Gi"
              cpu: "2000m"
          volumeMounts:
            - name: ollama-models
              mountPath: /root/.ollama
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0"
          # 모델 다운로드를 위한 init container 또는 post-start hook
          lifecycle:
            postStart:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    sleep 10
                    ollama pull gemma2:2b
          livenessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/tags
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
      volumes:
        - name: ollama-models
          emptyDir: {}
---
# Ollama Service
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
  namespace: rag-system
  labels:
    app: ollama
spec:
  selector:
    app: ollama
  ports:
    - name: http
      port: 11434
      targetPort: 11434
  type: ClusterIP
